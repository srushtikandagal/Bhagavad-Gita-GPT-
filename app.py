"""
GitaGPT â€“ Englishâ€‘only Streamlit chatbot.

â€¢ adult answer + kid line + referenced verses (IAST)
â€¢ shows â€œLoading embedding vectorsâ€¦â€ once at startup
â€¢ shows ğŸ¤” Thinking spinner for each question
â€¢ uses Groq gemmaâ€‘2Â 9Bâ€‘IT  (put GROQ_API_KEY in .env)
"""

import os, re, json, textwrap, time
import streamlit as st
from dotenv import load_dotenv
from io import StringIO

from langchain_core.prompts import ChatPromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain

# â”€â”€â”€ 0.  Env / API key check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
if not os.getenv("GROQ_API_KEY"):
    st.error("âš ï¸Â GROQ_API_KEY missing in .env"); st.stop()

# â”€â”€â”€ 1.  Page & CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config("Bhagavad Gita GPT)", "ğŸš©", layout="wide")
st.markdown("""
<style>
.section{font-size:19px;font-weight:700;margin:18px 0 6px;}
.answer{font-size:18px;margin:4px 0 12px;}
.ref-line{font-size:18px;font-weight:700;color:#0b3d91;margin:14px 0 2px;}
.shloka{font-size:17px;font-style:italic;margin:0 0 14px;}
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€ 2.  Sidebar (sample questions) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
samples = [
    "What is the significance of the Ká¹£etraâ€“Ká¹£etreÅ›vara concept?",
    "How does the Gita reconcile karma and free will?",
    "Explain JÃ±ÄnaÂ Yoga vs KarmaÂ Yoga.",
]
with st.sidebar:
    st.title("Bhagavad Gita GPT ğŸ“–")
    st.write("Sample questions:")
    for q in samples: st.caption(q)
    st.markdown("<small>Model can errÂ â€” verify verses.</small>", unsafe_allow_html=True)

# â”€â”€â”€ 3.  Embeddings + FAISS (cached, show spinner) â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.spinner("ğŸ”„Â Loading embedding vectorsâ€¦"):
    @st.cache_data(show_spinner=False)
    def load_emb():
        return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    if "emb" not in st.session_state:
        st.session_state.emb = load_emb()

@st.cache_resource(show_spinner=False)
def load_db():
    return FAISS.load_local("bhagvatgeeta_new",
                            embeddings=st.session_state.emb,
                            allow_dangerous_deserialization=True)
if "db" not in st.session_state:
    st.session_state.db = load_db()

retriever = st.session_state.db.as_retriever()   # let FAISS decide k

# â”€â”€â”€ 4.  LLM (cached) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def load_llm():
    return ChatGroq(model="gemma2-9b-it", max_tokens=4096)
if "llm" not in st.session_state:
    st.session_state.llm = load_llm()

# â”€â”€â”€ 5.  Long English prompt with your rules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
prompt_template = textwrap.dedent("""
O Partha,

Task: Answer questions based on the BhagavadÂ Gita in **English**, using the provided context.

InstructionsÂ (abridged):
â€¢ Retrieve relevant verses and summarise the key points.  
â€¢ Mention chapterÂ & verse numbers and quote the shlokas (IAST).  
â€¢ Begin with â€œOÂ Parthaâ€ and end with â€œJaiÂ ShriÂ Krishnaâ€.  
â€¢ Maintain a respectful tone, stay concise, accurate, focused, no programming help, no personal opinions outside the Gita.

If greeted, greet; if thanked, thank; if forced offâ€‘topic, reply â€œSorry, JaiÂ ShriÂ Krishna!â€.  
If unsure, say â€œIâ€™m not sure yet, please ask something else. JaiÂ ShriÂ Krishnaâ€.

<context>
{context}
</context>
Question: {input}
""")

prompt = ChatPromptTemplate.from_template(prompt_template)

# â”€â”€â”€ 6.  Retrieval + LLM chain â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
chain = create_retrieval_chain(
    retriever,
    create_stuff_documents_chain(st.session_state.llm, prompt)
)

# â”€â”€â”€ 7.  Stream helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def stream_words(text, speed=0.03):
    for w in text.split():
        yield w + " "
        time.sleep(speed)

# â”€â”€â”€ 8.  Chat history helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "hist" not in st.session_state: st.session_state.hist=[]
def log(role, body): st.session_state.hist.append({"role": role, "content": body})
def replay():        # show old messages on reload
    for m in st.session_state.hist:
        with st.chat_message(m["role"]):
            st.markdown(m["content"], unsafe_allow_html=True)

# â”€â”€â”€ 9.  Main loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
replay()
query = st.chat_input("Ask your Gita questionâ€¦")
if query:
    # 9â€‘a.  Show the userâ€™s message immediately
    with st.chat_message("user"):
        st.markdown(query)
    log("user", query)

    # 9â€‘b.  Generate the answer (spinnerâ€¯â†’â€¯LLM call)
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤”Â Thinkingâ€¦"):
            result = chain.invoke({"input": query})
        raw = result["answer"]          # full answer text

        # 9â€‘c.  **Stream** the words so the user sees them right away
        def word_gen(text: str):
            for w in text.split():
                yield w + " "
                time.sleep(0.03)        # typing speedâ€‘feel

        st.write_stream(word_gen(raw))  # <-- builtâ€‘in Streamlit streaming
        log("assistant", raw)
